---
title: "Rural hospitals in financial distress: The ethics of holding hospitals in underserved communities to capitalist standards"
author: "Razmin Bari"
date: "11/12/24"
output:
  pdf_document:
    latex_engine: xelatex
    keep_tex: true
header-includes:
  - \usepackage[12pt]{extsizes}
geometry: margin=0.5in
---

# Introduction

Rural hospitals in the United States are responsible for the healthcare needs of a particularly under-served portion of the population to whom other healthcare facilities may not be within feasible distances. Unfortunately, they have been at increasing risk of closure over the past few decades. Negative profit margins have been hypothesized to be the reason, and so researchers at the North Carolina Rural Health Research Program have been putting in considerable efforts to develop a model that can reliably predict whether a rural hospital will fall into financial distress (Malone et al.). Ideally, the model proposed in the article titled "An updated model of rural hospital financial distress" would flag the hospitals at high risk of closure within the next two years, which would then allow concerned authorities to bring forth relevant interventions such as increased funding.

  The first part of this final project will recreate the statistical analysis done in the aforementioned paper (the code for which is currently not publicly available) using a slimmed version of the paper's analytic dataset^[obtained via direct correspondence with the first author, Dr. Tyler L. Malone, University of North Carolina at Chapel Hill]. This part also includes simulations to compare how the model performs on similar datasets. The second part of the paper will analyze the normative concerns that may rise from using such a model in real-world settings, and debate whether the methods used inherently counter some of the concerns.

# [1] Analysis of Methods
## Data
The dataset I utilize here is a de-identified version of the dataset used in the paper's original analysis. It includes the following covariates that can be divided into four sub-domains:

(A) financial performance: (1) hospital profitability, (2) uncompensated care, (3) outpatient revenue and CAHMPAS score (a performance metric based on benchmarks set by Critical Access Hospital Measurement and Performance Assessment System),

(B) government reimbursement: (4) Critical Access Hospital (CAH) status, (5) Medicare outpatient payer mix expressed as a percentage of all outpatient charges, (6) ratio of Medicare Advantage and cost plan days to traditional Medicare acute care days, (7) Medicaid-to-Medicare fee index, and (8) Medicaid payer mix expressed as a percentage of all patient charges,

(C) organizational traits: (9) ownership, and (10) system affiliation,

(D) market characteristics: (11) competition

  The original analytic dataset included four more variables that the researchers do not wish to disclose publicly at this time. Hence, any coefficients calculated going forward will not be the same as the original analysis, but should still yield comparable results.

  Three binary financial distress outcomes were chosen for consideration: negative cash flow margin (a profitability metric), negative equity and hospital closure. This data set consists of 46200 observations owing to its 'stacked' nature: there are multiple rows for each hospital-year (one row for each combination of hospital, year, and type of financial distress outcome). Rows with any missing data is removed and so, the complete case analysis was conducted on 42226 observations.

## Recreating original probit regression analysis
The probit regression model was specified as follows:

  Financial distress indicator = $\beta_0 + \sum_{i=1}^p \beta_i * X_i + \epsilon$

where $\beta_0$ is the intercept, $\beta_i$ are the coefficients for the predictors $X_i$, and $\epsilon$ is the error term.

  Maintaining the paper's decision to not report the uninterpretable probit coefficients, here are the statistically significant Average Marginal Effects (AMEs) given a one standard deviation change in the covariates, along with corresponding p-values:

```{r, include = FALSE}
# Load libraries
library(tidyverse)
library(datawizard)
library(MASS)
library(margins) # summary function here overrides the basic R function
library(pROC)
library(caret)

# Load dataset
data <- data_read("C:/Users/razmi/OneDrive - University of North Carolina at Chapel Hill/STOR390/FDI.dta")

# Drop rows with missing data (complete case analysis)
data <- data %>% drop_na() # 3947 obs dropped

str(data)
summary(data)

probit_full <- glm(financial_distress_indicator ~ total_margin +
                         total_margin_tminus1 + total_margin_tminus2 +
                         outpatient_to_total_revenue + uncompensated_care +
                         pct_cahmpas_benchmarks_met + cah_indicator +
                         medicare_payer_mix + medicare_advantage_ratio +
                         medicaid_to_medicare_fee_index + medicaid_payer_mix +
                         forprofit_indicator + system_affiliation_indicator +
                         log_distance_to_g100bed_hospital +
                         financial_distress_type,
                       
                       data = data,
                       family = binomial(link = "probit"))

summary(probit_full)

# AMEs
AME_full <- summary(margins(probit_full))

AME_ss <- subset(AME_full, p < 0.05)

AME_ss_table <- AME_ss %>%
  dplyr::mutate(Description = c("CAH indicator variable", 
                                "/Negative Cash Flow Margin/",
                                "/Negative Equity/",
                                "For-profit indicator",
                                "Percent Medicare outpatient payer mix",
                                "Percent outpatient to total revenue",
                                "Percent CAHMPAS benchmarks met (2 years)",
                                "System affiliation",
                                "Percent total margin, year t", 
                                "Percent total margin, year t - 1", 
                                "Percent total margin, year t - 2", 
                                "Uncompensated care as a percentage of operating expenses"
                                ),
         Variable = c('cah_indicator', 'financial_distress_typeNegative cash flow margin', 
                      'financial_distress_typeNegative equity', 
                      'forprofit_indicator',
                      'medicare_payer_mix', 'outpatient_to_total_revenue',
                      'pct_cahmpas_benchmarks_met', 
                      'system_affiliation_indicator',
                      'total_margin', 'total_margin_tminus1', 
                      'total_margin_tminus2',
                       'uncompensated_care'
                      ),
         `Average marginal effect` = AME_ss$AME,
         `Standard error` = AME_ss$SE,
         `p-value` = AME_ss$p) %>%
  dplyr::select(Description, Variable, `Average marginal effect`, `Standard error`, `p-value`)
# Generate the LaTeX table
library(knitr)
library(kableExtra)
```

```{r, echo = FALSE, warning=FALSE}
kable(
  AME_ss_table,
  booktabs = TRUE,
  digits = 5,
  caption = "Average Marginal Effects for Financial Distress Model"
) %>%
  kable_styling(
    font_size = 8,
    latex_options = c("striped", "scale_down")
  ) %>%
  column_spec(1, width = "3em") %>% 
  column_spec(2, width = "10em") %>%
  column_spec(3, width = "15em") %>%
  column_spec(4:6, width = "6em")
```

  To clarify with an example, an increase of one standard deviation in uncompensated care as a percentage of operating expenses increases the probability of future financial distress by 1.3%. While the AME values do not entirely match up as expected, the values still show strong alignment to the results in Malone et al.

  The stacked nature of the dataset has allowed the model to be optimally parsimonious. It also increased the risk of multicollinearity. Hence, the Variance Inflation Factor (VIF) was calculated, and no predictors had high VIF values, suggesting that multicollinearity among covariates is not a significant concern for the model.

```{r, include = FALSE}
library(car)

vif_values <- vif(probit_full)
vif_values
```


  To evaluate the model's performance, the area under the receiver operating characteristic (ROC) curve (AUC) was computed for the test dataset. The AUC value of 0.867 indicates strong predictive power for the model. The following ROC curve was plotted to visually assess the trade-off between sensitivity and specificity at various thresholds:

```{r, include = FALSE}
# Predict probabilities for the test set
data_full_test <- data %>% filter(training_set_indicator == 0)

data_full_test <- data_full_test %>% 
  mutate(pred_full = predict(probit_full, 
                                 newdata = data_full_test, 
                                 type = "response"))

# AUC Calculation
roc_full <- roc(data_full_test$financial_distress_indicator, 
                    data_full_test$pred_full)
auc_full <- auc(roc_full)
cat("AUC for Full Model:", round(auc_full, 3), "\n") 
# 0.867
```
```{r, echo = FALSE}
# Plot ROC Curve
plot(roc_full, main = "ROC Curve", col = "purple")
text(0.6, 0.4, paste("AUC =", round(auc_full, 3)), col = "purple")
```


## Simulation Study
To assess the robustness of the model, I simulated a dataset resembling the original data by sampling from the continuous variables' means and covariance structure, and simulating binary and categorical variables based on their observed proportions in the dataset. The simulated dataset was used to fit the same probit model. The model was then evaluated on this simulated data, and the confusion matrix revealed a classification accuracy of 89.2%. The AUC for the simulated data was 0.847, showing comparable but slightly reduced model performance. The ROC curves for both the simulated and original data are below:

```{r, include = FALSE}
data <- data_read("C:/Users/razmi/OneDrive - University of North Carolina at Chapel Hill/STOR390/FDI.dta")
data <- data %>% drop_na() # 3947 obs dropped

set.seed(123)

# Extract continuous variables from the original data
continuous_vars <- c("total_margin", "total_margin_tminus1", "total_margin_tminus2", 
                     "outpatient_to_total_revenue", "uncompensated_care", 
                     "pct_cahmpas_benchmarks_met", "medicare_payer_mix", 
                     "medicare_advantage_ratio", "medicaid_to_medicare_fee_index", 
                     "medicaid_payer_mix", "log_distance_to_g100bed_hospital")
data_cont <- data[continuous_vars]

means <- colMeans(data_cont, na.rm = TRUE)  # Calculate means for continuous variables
cov_matrix <- cov(data_cont, use = "complete.obs")  # Calculate covariance matrix

n <- 42226  # Number of observations (same as in the actual dataset)

# Simulate continuous predictors using multivariate normal distribution
X_cont <- mvrnorm(n, mu = means, Sigma = cov_matrix)
colnames(X_cont) <- continuous_vars

# Simulate binary variables (assuming proportions from real data):
cah_indicator <- rbinom(n, size = 1, prob = mean(data$cah_indicator, na.rm = TRUE))
forprofit_indicator <- rbinom(n, size = 1, prob = mean(data$forprofit_indicator, na.rm = TRUE))
system_affiliation_indicator <- rbinom(n, size = 1, prob = mean(data$system_affiliation_indicator, na.rm = TRUE))

# For financial distress type (categorical variable, simulate based on observed proportions):
financial_distress_type <- sample(c("Negative cash flow margin", "Negative equity", "Hospital closure"), 
                                   n, replace = TRUE, 
                                   prob = prop.table(table(data$financial_distress_type)))

# Combine the simulated variables into a data frame
data_sim <- data.frame(X_cont,
                       cah_indicator, 
                       forprofit_indicator, 
                       system_affiliation_indicator, 
                       financial_distress_type)

# Coefficients from the real probit model
coefficients <- c(Intercept = -1.577466, 
                  total_margin = -0.179609, 
                  total_margin_tminus1 = -0.045296, 
                  total_margin_tminus2 = -0.121104, 
                  outpatient_to_total_revenue = -0.096233, 
                  uncompensated_care = 0.094297, 
                  pct_cahmpas_benchmarks_met = -0.326124, 
                  cah_indicator = 0.120538, 
                  medicare_payer_mix = -0.061746, 
                  medicare_advantage_ratio = -0.001059, 
                  medicaid_to_medicare_fee_index = -0.007311, 
                  medicaid_payer_mix = 0.011893, 
                  forprofit_indicator = 0.304215, 
                  system_affiliation_indicator = 0.047793,
                  log_distance_to_g100bed_hospital = -0.002979,
                  `financial_distress_typeNegative cash flow margin` = 2.000227, 
                  `financial_distress_typeNegative equity` = 1.397609)

# Prepare the model matrix (including categorical variables)
X_matrix <- model.matrix(~ total_margin + total_margin_tminus1 + total_margin_tminus2 
                         + outpatient_to_total_revenue + uncompensated_care
                         + pct_cahmpas_benchmarks_met + cah_indicator 
                         + medicare_payer_mix + medicare_advantage_ratio 
                         + medicaid_to_medicare_fee_index 
                         + medicaid_payer_mix + forprofit_indicator 
                         + system_affiliation_indicator 
                         + log_distance_to_g100bed_hospital 
                         + financial_distress_type, data = data_sim)

# Simulate the latent variable (linear predictor)
latent_variable <- X_matrix %*% coefficients + rnorm(n)

# Simulate financial distress indicator based on the latent variable (probit link function)
data_sim$financial_distress_indicator <- as.numeric(pnorm(latent_variable) > 0.5)

# Fit the original model on the simulated data
probit_model_sim <- glm(financial_distress_indicator ~ total_margin + 
                          total_margin_tminus1 + 
                          total_margin_tminus2 + outpatient_to_total_revenue + 
                          uncompensated_care + pct_cahmpas_benchmarks_met + 
                          cah_indicator + medicare_payer_mix + 
                          medicare_advantage_ratio + 
                          medicaid_to_medicare_fee_index + 
                          medicaid_payer_mix + forprofit_indicator + 
                          system_affiliation_indicator + 
                          log_distance_to_g100bed_hospital + 
                          financial_distress_type,
                        data = data_sim, family = binomial(link = "probit"))

predicted_probabilities <- predict(probit_model_sim, type = "response")

# Convert probabilities to binary 
predicted_class <- ifelse(predicted_probabilities > 0.5, 1, 0)

# Confusion matrix to evaluate model performance
conf_matrix <- confusionMatrix(factor(predicted_class), factor(data_sim$financial_distress_indicator))

# conf_matrix

accuracy <- sum(predicted_class == data_sim$financial_distress_indicator) / length(predicted_class)
cat("Accuracy of the model on the simulated data: ", accuracy, "\n")

# AUC & ROC curves
roc_sim <- roc(data_sim$financial_distress_indicator, predicted_probabilities)
auc_sim <- auc(roc_sim)
```

```{r, echo = FALSE}
plot(roc_full, col = "purple", lwd = 2, main = "Comparison of ROC Curves")
lines(roc_sim, col = "blue", lwd = 2)
legend("bottomright", legend = c("Original Model", "Simulation 1"), 
       col = c("purple", "blue"), lwd = 2)
text(0.6, 0.3, paste("AUC =", round(auc_full, 3)), col = "purple")
text(0.6, 0.4, paste("AUC =", round(auc_sim, 3)), col = "blue")

```

## Sensitivity Analysis: Modifying Proportion of Negative Profit Margin
  In a further analysis, I simulated a scenario where the proportion of hospitals with a negative total margin was increased to 60%. The probit model was refitted to this modified dataset, and the confusion matrix revealed that the classification accuracy of 89.2% was maintained. The ROC curve comparison showed a slight reduction in model performance (AUC = 0.844) compared to the original model, as presented below:

```{r, include=FALSE}
set.seed(123)

# Simulate an increase in the percentage of hospitals with negative total margin
data_sim_mod <- data_sim
neg_margin_count <- sum(data_sim_mod$total_margin < 0)
new_neg_margin_count <- round(nrow(data_sim_mod) * 0.60) 
# ^^Increase the proportion of negative margins to 60%

indices_to_modify <- sample(which(data_sim_mod$total_margin >= 0), 
                            size = new_neg_margin_count - neg_margin_count, 
                            replace = FALSE)
data_sim_mod$total_margin[indices_to_modify] <- runif(length(indices_to_modify), 
                                                      min = -5, max = -0.1)

summary(data_sim_mod$total_margin)

# Fitting probit model
probit_sim_mod <- glm(financial_distress_indicator ~ total_margin + 
                          total_margin_tminus1 + 
                          total_margin_tminus2 + outpatient_to_total_revenue + 
                          uncompensated_care + pct_cahmpas_benchmarks_met + 
                          cah_indicator + medicare_payer_mix + 
                          medicare_advantage_ratio + 
                          medicaid_to_medicare_fee_index + 
                          medicaid_payer_mix + forprofit_indicator + 
                          system_affiliation_indicator + 
                          log_distance_to_g100bed_hospital + 
                          financial_distress_type,
                      data = data_sim_mod, family = binomial(link = "probit"))

AME_sim2 <- summary(margins(probit_sim_mod))

predicted_probabilities_mod <- predict(probit_sim_mod, type = "response")


# Convert probabilities to binary 
predicted_class_mod <- ifelse(predicted_probabilities_mod > 0.5, 1, 0)

# Confusion matrix to evaluate model performance
conf_matrix <- confusionMatrix(factor(predicted_class_mod), factor(data_sim_mod$financial_distress_indicator))



accuracy <- sum(predicted_class == data_sim$financial_distress_indicator) / length(predicted_class)
cat("Accuracy of the model on the simulated data: ", accuracy, "\n")


# ROC curves
roc_curve_mod <- roc(data_sim_mod$financial_distress_indicator, predicted_probabilities_mod)
auc_sim_mod <- auc(roc_curve_mod)
cat("AUC (Area Under the Curve) of the model on the simulated data: ", auc_sim_mod, "\n")
```

```{r, echo=FALSE}
plot(roc_full, col = "purple", lwd = 2, main = "Comparison of ROC Curves")
lines(roc_curve_mod, col = "red", lwd = 2)
legend("bottomright", legend = c("Original Model", "Simulation 2"), 
       col = c("purple", "red"), lwd = 2)
text(0.6, 0.3, paste("AUC =", round(auc_full, 3)), col = "purple")
text(0.6, 0.4, paste("AUC =", round(auc_sim_mod, 3)), col = "red")
```

# [2] Analysis of Normative Consideration

Ideally, this predictive model would serve as a decision-making tool to identify hospitals at risk of financial distress, potentially increasing funding or driving policy changes to support these institutions. However, a critical limitation of this approach is its failure to account for the possibility of (reverse) causation among the covariates and the financial distress outcomes. For instance, a hospital's negative cash flow margin—representing low profitability—could itself be the cause of certain covariate values, such as high uncompensated care or low outpatient revenue. In such cases, the model might simply be reflecting symptoms of financial distress rather than identifying the root causes. If profitability becomes the primary determinant for funding or intervention based on the model’s predictions, a hospital’s ability to demonstrate financial health may unjustly dictate whether it receives the support necessary to remain operational.  

  This concern is particularly salient given that one of the statistically significant predictors in the Malone et al. study was percent total margin, often used as a proxy for profitability. Indeed, three measures of percent total margin are included, including values from up to two years ago for a given observation. In my own analysis above, an increase of one standard deviation in percent total margin showed a statistically significant decrease in the probability of future financial distress by about 2.5%. It is worthwhile to note that the model's predictive accuracy does not degrade when the proportion of hospitals with negative profit margins was increased in the simulation study. This shows that the model is not as heavily swayed by variables of profitability as one might think. On the other hand, the decrease in AUC value does suggest some loss of predictive power which requires further analysis to be sure that inequities are not exacerbated.

  There might also be a concern that the model might exacerbate inherent classist realities present in the data. To highlight a way this is possible, I present a table below of  True Positive Rates (TPR) and False Positive Rates (FPR) for classification by the model across the *forprofit_indicator* values. 

```{r, echo = FALSE}
data_forprofit <- data %>% filter(forprofit_indicator == 1)
data_nonprofit <- data %>% filter(forprofit_indicator == 0)

data_forprofit <- data_forprofit %>% 
  mutate(predicted_prob = predict(probit_full, newdata = ., type = "response"))

data_nonprofit <- data_nonprofit %>% 
  mutate(predicted_prob = predict(probit_full, newdata = ., type = "response"))

thresholds <- seq(0, 1, by = 0.1)

tpr_fpr_forprofit <- sapply(thresholds, function(threshold) {
  pred <- ifelse(data_forprofit$predicted_prob >= threshold, 1, 0)
  tpr <- mean(pred[data_forprofit$financial_distress_indicator == 1] == 1) # True Positive Rate
  fpr <- mean(pred[data_forprofit$financial_distress_indicator == 0] == 1) # False Positive Rate
  c(tpr, fpr)
})

tpr_fpr_nonprofit <- sapply(thresholds, function(threshold) {
  pred <- ifelse(data_nonprofit$predicted_prob >= threshold, 1, 0)
  tpr <- mean(pred[data_nonprofit$financial_distress_indicator == 1] == 1) # True Positive Rate
  fpr <- mean(pred[data_nonprofit$financial_distress_indicator == 0] == 1) # False Positive Rate
  c(tpr, fpr)
})

# Print TPR and FPR results for comparison
tpr_fpr_results <- data.frame(
  Threshold = thresholds,
  TPR_ForProfit = tpr_fpr_forprofit[1, ],
  TPR_NonProfit = tpr_fpr_nonprofit[1, ],
  FPR_ForProfit = tpr_fpr_forprofit[2, ],
  FPR_NonProfit = tpr_fpr_nonprofit[2, ]
)

print("Equalized Odds Assessment Results:")
print(tpr_fpr_results)

```
  FPRs for for-profit hospitals are consistently higher than for non-profits at every threshold above 0. The differences in FPRs suggest that the model is more likely to misclassify non-distressed for-profits as distressed compared to non-profits. However, the differences in the rates do not exceed their corresponding thresholds and so, equalized odds can still be tentatively assumed. The persisting differences may simply be attributed to difference in proportion of for-profit and non-profit hospitals in the dataset. It is worthwhile to note that the model had high accuracy rates of prediction even in the simulated datasets.

  Regardless, employing such a model raises profound ethical concerns. From a consequentialist perspective, the ethical evaluation of an action is based on its outcomes. Consequentialists argue that an action is morally right if it leads to the greatest good for the greatest number of people. Employing a model that prioritizes the monetary interests of hospital owners over the well-being of the community fails this test. By allowing financial metrics to dictate intervention decisions, such an approach could lead to the closure of hospitals that are vital to underserved communities, resulting in widespread suffering and reduced access to healthcare. The negative consequences for large rural populations far outweigh any benefits accrued by a small group of stakeholders.

  For deontologists, morality is determined by adherence to the inherent dignity of moral agents. Deontologists would critique this model for its instrumentalization of patients, reducing them to mere means to lead to the end that is hospital profitability. Regardless of geographic or economic circumstances, patients have an inalienable right to proper healthcare. A system that subordinates this right to financial considerations breaches the categorical imperative to treat individuals as ends in themselves. 

  Credit has to be given to the researchers here however, since the original intention (an important aspect of Kantian Deontology) was to aid at-risk hospitals. Unfortunately, this is not a robust enough point, especially taking into what exactly counts as "helping". If helping at-risk hospitals involves decisions like cutting services or closing facilities, these actions could directly harm patients, violating their dignity and autonomy.

  Virtue ethicists evaluate actions based on the character and virtues of the decision-makers involved. This ethical framework emphasizes cultivating virtues such as compassion, justice, and beneficence. A model that prioritizes corporate greed over the moral imperative to care for vulnerable patients reflects a failure to embody these virtues. It is inconsistent with the character of a compassionate healthcare provider, whose duty is to prioritize alleviating suffering and promoting well-being. From this perspective, a profit-driven approach undermines the moral integrity of healthcare systems, as it replaces virtuous motivations with self-serving goals.

# Conclusion
By prioritizing profitability as a criterion for allocating resources, usage of the model outlined in the chosen paper risks reinforcing systemic inequities. For rural hospitals serving economically disadvantaged populations, it is important to keep in mind low profitability often stems from structural factors like high poverty rates or inadequate insurance coverage among patients.

  My recreation of the statistical analysis as well as my analysis of ethical concerns highlights an issue that becomes even more urgent in the current climate, where rural hospitals face growing financial pressures and are at risk of closure. The collapse of these institutions leaves rural communities increasingly vulnerable to complete healthcare inaccessibility. Consequently, it is imperative that any predictive model used to guide policy decisions on rural hospitals moves beyond profit-maximization metrics. Instead, models should incorporate community-centered measures, ensuring that funding and interventions align with the healthcare needs of underserved populations.

# References
1. Malone, Tyler L, et al. “An Updated Model of Rural Hospital Financial Distress.” The Journal of Rural Health, 3 Oct. 2024, https://doi.org/10.1111/jrh.12882.

```{r, echo = FALSE}
# Instructor comments:
# nice job carefully detailing your data set and any differences it has with the original.  

# last sentence of page 2 subject-verb agreement.  Rows... is (are) removed

# I could use a fuller description of the probit model.  what assumptions are placed on the epsilon?  discuss why a probit model is the correct one to use. 

# in interpretation at bottom of page 3, you need "holding all else equal" since this is a multiple regression.  

# elaborate on what you mean by the simulated data was fit to the same probit model.  you mean you re-estimated the parameters for the same set of covariates in a probit model correct?  not that you simply coerced the parameters to be the same and saw how the AUC/ROC would look under the simulated data on the same parameters?

# really nice discussion of limitations.  

# I would figure out a way to make the equalized odds figure as visually appealing as the others presented in this paper.  make it a new table rather than reporting the raw output


# I really enjoy your addressing the same moral concern from each of the three frameworks.  this illustrates that while they can (at times) disagree, they are often completely consistent.  in the instances where they are consistent, we get the most compelling argument.  

 

unless otherwise stated, full points awarded according to rubric:

analysis of method 9/10 

grammar: 2/3 

figures/formulas: 4/5 
```
